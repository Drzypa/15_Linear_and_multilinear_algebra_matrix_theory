\documentclass[12pt]{article}
\usepackage{pmmeta}
\pmcanonicalname{CharacteristicMatrixOfDiagonalElementCrosssection}
\pmcreated{2013-03-22 15:29:45}
\pmmodified{2013-03-22 15:29:45}
\pmowner{lars_h}{9802}
\pmmodifier{lars_h}{9802}
\pmtitle{characteristic matrix of diagonal element cross-section}
\pmrecord{4}{37354}
\pmprivacy{1}
\pmauthor{lars_h}{9802}
\pmtype{Theorem}
\pmcomment{trigger rebuild}
\pmclassification{msc}{15A30}

\endmetadata

\usepackage{amsmath,amsfonts,amssymb,amsthm}

\newtheorem*{lemma}{Lemma}

\newcommand{\mc}{\mathcal}
\newcommand{\vek}{\mathbf}
\newcommand{\Mat}{\mathrm{M}}
\begin{document}
Denote by $\Mat_n(\mc{K})$ the set of all $n \times n$ matrices over 
$\mc{K}$. Let \(d_i\colon \Mat_n(\mc{K}) \longrightarrow \mc{K}\) be 
the function which extracts the $i$th diagonal element of a matrix. 
Finally denote by $[n]$ the set $\{1,\dotsc,n\}$. 


\begin{lemma}
  Let $\mc{K}$ be a field. 
  Let a sequence \(A_1,\dotsc,A_r \in \Mat_n(\mc{K})\) of upper 
  triangular matrices be given, and denote by \(\mc{A} \subseteq 
  \Mat_n(\mc{K})\) the unital algebra generated by these matrices. 
  For every sequence \(\lambda_1,\dotsc,\lambda_r \in \mc{K}\) of 
  scalars there exists a matrix \(C \in \mc{A}\) such that
  $$
    d_i(C) = \begin{cases}
      1& \text{if \(d_i(A_k)=\lambda_k\) for all \(k \in [r]\),}\\
      0& \text{otherwise}
    \end{cases}
  $$
  for all \(i \in [n]\).
\end{lemma}

A diagonal element of an upper triangular matrix is of course an 
eigenvalue of that matrix, so the particular $\lambda_1,\dotsc,\lambda_r$ 
that one plugs into this lemma is typically either a sequence of 
eigenvalues for the given matrices, or a sequence of values that 
one thinks may be eigenvalues for these matrices. 
The ``cross-section'' in the title refers to that there is one 
$\lambda_k$ for each matrix $A_k$.

The result gets more interesting if one knows something more about 
$\mc{A}$ than what was explicitly required above. A particular example 
is that if the given matrices commute then $\mc{A}$ will be a 
\PMlinkname{commutative}{Commutative} algebra and consequently 
$C$ will commute with all of the given matrices as well.

\PMlinkescapeword{row}
\PMlinkescapeword{independent}

\begin{proof}
  Let $S$ be the set of those row indices $i$ for which $d_i(C)$ 
  should be $0$, i.e.,
  $$
    S = \bigl\{ i \in [n] \,\bigm|\, 
      \text{\(d_i(A_k) \neq \lambda_k\) for some \(k \in [r]\)}
    \bigr\}
    \text{,}
  $$
  and for each \(i \in S\) let \(k_i \in [r]\) be such that 
  \(d_i(A_{k_i}) \neq \lambda_{k_i}\). Define
  $$
    B_i = \begin{cases}
      A_{k_i} - d_i(A_{k_i})I & \text{if \(i \in S\),}\\
      I& \text{otherwise}
    \end{cases}
  $$
  for all \(i \in [n]\) and let \(B = \prod_{i=1}^n B_i\). Since all 
  the matrices involved are upper triangular, a diagonal element in $B$ 
  is simply the product of the corresponding diagonal elements in all 
  of $B_1,\dotsc,B_n$. If \(i \in S\) then \(d_i(B_i) = 
  d_i\bigl( A_{k_i} -\nobreak d_i(A_{k_i}) I\bigr) = 
  d_i(A_{k_i}) - d_i(A_{k_i}) = 0\) and thus \(d_i(B) = 0\) for \(i 
  \in S\). If instead \(i \in [n] \setminus S\) then
  \begin{multline*}
    d_i(B) = 
    \prod_{j=1}^n d_i(B_i) =
    \prod_{j \in S} d_i\bigl( A_{k_j} - d_j(A_{k_j})I \bigr) = \\ =
    \prod_{j \in S} \bigl( d_i(A_{k_j}) - d_j(A_{k_j}) \bigr) =
    \prod_{j \in S} \bigl( \lambda_{k_j} - d_j(A_{k_j}) \bigr) =: b
    \text{.}
  \end{multline*}
  This $b$ is by definition of $k_j$ nonzero, and since it is 
  independent of $i$ it follows that it is the only nonzero value of a 
  diagonal element of $B$. Hence the wanted \(C = b^{-1} B\).
\end{proof}
%%%%%
%%%%%
\end{document}
