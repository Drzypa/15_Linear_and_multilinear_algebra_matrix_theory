\documentclass[12pt]{article}
\usepackage{pmmeta}
\pmcanonicalname{ElementaryMatrixOperationsAsRankPreservingOperations}
\pmcreated{2013-03-22 19:22:57}
\pmmodified{2013-03-22 19:22:57}
\pmowner{CWoo}{3771}
\pmmodifier{CWoo}{3771}
\pmtitle{elementary matrix operations as rank preserving operations}
\pmrecord{18}{42337}
\pmprivacy{1}
\pmauthor{CWoo}{3771}
\pmtype{Definition}
\pmcomment{trigger rebuild}
\pmclassification{msc}{15-01}
\pmclassification{msc}{15A33}
\pmclassification{msc}{15A03}

\endmetadata

\usepackage{amssymb,amscd}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{multicol}

% used for TeXing text within eps files
%\usepackage{psfrag}
% need this for including graphics (\includegraphics)
%\usepackage{graphicx}
% for neatly defining theorems and propositions
\usepackage{amsthm}
% making logically defined graphics
%%\usepackage{xypic}
\usepackage{pst-plot}

% define commands here
\newcommand*{\abs}[1]{\left\lvert #1\right\rvert}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{ex}{Example}
\newcommand{\real}{\mathbb{R}}
\newcommand{\pdiff}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\mpdiff}[3]{\frac{\partial^#1 #2}{\partial #3^#1}}

\begin{document}
Let $M$ be a matrix over a division ring $D$.  An \emph{elementary operation} on $M$ is any one of the eight operations below:
\begin{multicols}{2}
\begin{enumerate}
\item exchanging two rows
\item exchanging two columns
\item adding one row to another
\item adding one column to another
\item right multiplying a non-zero scalar to a row
\item left multiplying a non-zero scalar to a row
\item right multiplying a non-zero scalar to a column
\item left multiplying a non-zero scalar to a column
\end{enumerate}
\end{multicols}
We want to determine the effects of these operations on the various ranks of $M$.  To facilitate this discussion, let $M=(a_{ij})$ be an $n\times m$ matrix and $M'=(b_{ij})$ be the matrix after an application of one of the operations above to $M$.  In addition, let $v_i=(a_{i1},\cdots, v_{im})$ be the $i$-th row of $M$, and $w_i=(b_{i1},\cdots, b_{im})$ be the $i$-th row of $M'$.  In other words,
$$
M=
\begin{pmatrix}
v_1 \\
\vdots \\ 
v_n
\end{pmatrix}
=
\begin{pmatrix}
a_{11} & \cdots & a_{1m} \\
\vdots & \ddots & \vdots \\ 
a_{n1} & \cdots & a_{nm}
\end{pmatrix}
\xrightarrow[\textrm{operation}]{\textrm{elementary}}
\begin{pmatrix}
b_{11} & \cdots & b_{1m} \\
\vdots & \ddots & \vdots \\ 
b_{n1} & \cdots & b_{nm}
\end{pmatrix}
=
\begin{pmatrix}
w_1 \\
\vdots \\ 
w_n
\end{pmatrix}
=
M'
$$
Finally, let $d$ be the left row rank of $M$.

\begin{prop}  Row and column exchanges preserve all ranks of $M$.  \end{prop}
\begin{proof}  Clearly, exchanging two rows of $M$ do not change the subspace generated by the rows of $M$, and therefore $d$ is preserved.  

As exchanging rows do not affect $d$, let us assume that rows have been exchanged so that the first $d$ rows of $M$ are left linearly independent.

Now, let $M'$ be obtained from $M$ by exchanging columns $i$ and $j$.  So $w_1,\ldots, w_n$ are vectors obtained respectively from $v_1,\ldots, v_n$ by exchanging the $i$-th and $j$-th coordinates.  Suppose $r_1w_1+\cdots + r_dw_d=0$.  Then we get an equation $r_1b_{1k}+\cdots + r_d b_{dk}=0$ for $1\le k\le m$.  Rearranging these equations, we see that $r_1v_1 + \cdots + r_dv_d=0$, which implies $r_1=\cdots = r_d =0$, showing that $w_1,\ldots, w_d$  are left linearly independent.  This means that $d$ is preserved by column exchanges.

Preservation of other ranks of $M$ are similarly proved.
\end{proof}

\begin{prop} Additions of rows and columns preserve all ranks of $M$. \end{prop}
\begin{proof}  Let $M'$ be the matrix obtained from $M$ by replacing row $i$ by vector $v_i+v_j$, and let $V'$ be the left vector space spanned by the rows of $M'$.  Since $v_i+v_j\in V$, we have $V'\subseteq V$.  On other hand, $v_i=(v_i+v_j)-v_j \in V'$, so $V\subseteq V'$, and hence $V=V'$.

Next, let $w_1,\ldots, w_n$ be vectors obtained respectively from $v_1,\ldots, v_n$ such that the $i$-th coordinate of $w_k$ is the sum of the $i$-th coordinate of $v_k$ and the $j$-th coordinate of $v_k$, with all other coordinates remain the same.  Again, by renumbering if necessary, let $v_1,\ldots, v_d$ be left linearly independent.  Suppose $r_1w_1 + \cdots + r_iw_i+ \cdots + r_dw_d = 0$.  A similar argument like in the previous proposition shows that $r_1v_1+\cdots + (r_i+r_j)v_j + r_dv_d = 0$, which implies $r_1 =\cdots = r_i+r_j = \cdots r_d = 0$.  Since $r_i=0$, $r_j=0$ too.  This shows that $w_1,\ldots, w_d$ are left linearly independent, which means that $d$ is preserved by additions of columns.

Preservation of other ranks of $M$ are proved similarly.
\end{proof}

\begin{prop} Left (right) non-zero row scalar multiplication preserves left (right) row rank of $M$; left (right) non-zero column scalar multiplications preserves left (right) column rank of $M$.  \end{prop}
\begin{proof}  Let $w_1,\ldots, w_n$ be vectors obtained respectively from $v_1,\ldots, v_n$ such that the $i$-th vector $w_i=rv_i$, where $0\ne r\in D$, and all other $w_j$'s are the same as the $v_j$'s.  Assume that the first $d$ rows of $M$ are left linearly independent, and that $i\le d$.  Suppose $r_1w_1+\cdots + r_dw_d=0$.  Then $r_1v_1+ \cdots + r_i(rv_i) + \cdots r_dv_d = 0$, which implies $r_1 = \cdots = r_ir = \cdots = r_d = 0$.  Since $r\ne 0$, $r_i=0$, and therefore $w_1,\ldots, w_d$ are left linearly independent.

The others are proved similarly.
\end{proof}

\begin{prop} Left (right) non-zero row scalar multiplication preserves right (left) column rank of $M$; left (right) non-zero column scalar multiplication preserves right (left) row rank of $M$. \end{prop}
\begin{proof}
Let us prove that right multiplying a column by a non-zero scalar $r$ preserves the left row rank $d$ of $M$.  The others follow similarly.

Let $w_1,\ldots, w_n$ be vectors obtained respectively from $v_1,\ldots, v_n$ such that the $i$-th coordinate $b_{ik}$ of $w_k$ is $a_{ik}r$, where $a_{ik}$ is the $i$-th coordinate of $v_k$.  Suppose once again that the first $d$ rows of $M$ are left linearly independent, and suppose $r_1w_1 + \cdots + r_dw_d=0$.  Then for each coordinate $j$ we get an equation $r_1b_{1j}+\cdots + r_d b_{dj}=0$.  In particular, for the $i$-th coordinate, we have $r_1a_{1j}r+\cdots + r_d a_{dj}r=0$.  Since $r\ne 0$, right multiplying the equation by $r^{-1}$ gives us $r_1a_{1j}+\cdots + r_d a_{dj}=0$.  Re-collecting all the equations, we get $r_1v_1+\cdots +r_dw_d=0$, which implies that $r_1= \cdots = r_d = 0$, or that $w_1,\ldots, w_d$ are left linearly independent.
\end{proof}

%%%%%
%%%%%
\end{document}
